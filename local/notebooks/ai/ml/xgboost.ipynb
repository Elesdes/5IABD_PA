{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost Model to Predict Hand Movements Based On EMG Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"../calib_rec_tool/outputV2.csv\")\n",
    "df = df.drop(columns=[df.columns[0]])\n",
    "\n",
    "features_to_keep = [\n",
    "    \"sensor1\",\n",
    "    \"sensor2\",\n",
    "    \"sensor3\",\n",
    "    \"sensor4\",\n",
    "    \"sensor5\",\n",
    "    \"sensor6\",\n",
    "    \"sensor7\",\n",
    "    \"sensor8\",\n",
    "]\n",
    "X, Y = df[features_to_keep].to_numpy(), df.label.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Butterworth filter functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import butter, filtfilt\n",
    "\n",
    "\n",
    "def butter_lowpass(cutoff, fs, order=4):\n",
    "    nyquist = 0.5 * fs\n",
    "    normal_cutoff = cutoff / nyquist\n",
    "    b, a = butter(order, normal_cutoff, btype=\"low\", analog=False)\n",
    "    return b, a\n",
    "\n",
    "\n",
    "def lowpass_filter(data, cutoff=20, fs=1000, order=4):\n",
    "    b, a = butter_lowpass(cutoff, fs, order)\n",
    "    y = filtfilt(b, a, data, axis=0)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Segmenting the signal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def segment_signal(data, labels, window_size, overlap):\n",
    "    segments = []\n",
    "    segment_labels = []\n",
    "    for start in range(0, len(data) - window_size, window_size - overlap):\n",
    "        segment = data[start : start + window_size]\n",
    "        segment_label = labels[start]\n",
    "        segments.append(segment)\n",
    "        segment_labels.append(segment_label)\n",
    "    return np.array(segments), np.array(segment_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(segment):\n",
    "    features = [\n",
    "        np.mean(segment, axis=0),\n",
    "        np.var(segment, axis=0),\n",
    "        np.max(segment, axis=0),\n",
    "        np.min(segment, axis=0),\n",
    "    ]\n",
    "    return np.concatenate(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_emg_data(\n",
    "    data: pd.DataFrame, cutoff: int = 20, fs: int = 1000, window_size: int = 50\n",
    "):\n",
    "    filtered_data = lowpass_filter(data, cutoff, fs)\n",
    "    rectified_data = np.abs(filtered_data)\n",
    "    smoothed_data = np.array(\n",
    "        [\n",
    "            np.convolve(signal, np.ones(window_size) / window_size, mode=\"valid\")\n",
    "            for signal in rectified_data.T\n",
    "        ]\n",
    "    ).T\n",
    "    return smoothed_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "class XGBoostClassifier:\n",
    "    def __init__(self, seed=42):\n",
    "        self.seed = seed\n",
    "        self.clf = xgb.XGBClassifier()\n",
    "        self.le = LabelEncoder()\n",
    "        np.random.seed(seed)\n",
    "\n",
    "    def train(self, X_train, y_train):\n",
    "        y_train = self.le.fit_transform(y_train)\n",
    "        self.clf.fit(X_train, y_train)\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.clf.predict(X)\n",
    "\n",
    "    def accuracy(self, y_true, y_pred):\n",
    "        return accuracy_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import List\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Hyperparameters:\n",
    "    seed: int = 42\n",
    "    window_sizes: List[int] = [150, 200, 450]\n",
    "    overlaps: List[int] = [50]\n",
    "    cutoffs: List[int] = [10, 20]\n",
    "    sampling_frequencies: List[int] = [100, 200]\n",
    "    order: int = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "hyperparams = Hyperparameters()\n",
    "model = XGBoostClassifier(seed=hyperparams.seed)\n",
    "final_results = []\n",
    "\n",
    "for w_s in hyperparams.window_sizes:\n",
    "    for ol in hyperparams.overlaps:\n",
    "        for coff in hyperparams.cutoffs:\n",
    "            for f_s in hyperparams.sampling_frequencies:\n",
    "                print(\n",
    "                    f\"Starting:\\nWindow Size: {w_s} | Overlap: {ol} | Cutoff: {coff} | fs: {f_s}\"\n",
    "                )\n",
    "\n",
    "                preprocessed_emg_data = preprocess_emg_data(\n",
    "                    X, cutoff=coff, fs=f_s, window_size=w_s\n",
    "                )\n",
    "                segments, segment_labels = segment_signal(\n",
    "                    preprocessed_emg_data, y, w_s, ol\n",
    "                )\n",
    "                features = np.array([extract_features(segment) for segment in segments])\n",
    "\n",
    "                X_train, X_test, y_train, y_test = train_test_split(\n",
    "                    features, segment_labels, test_size=0.4, random_state=model.seed\n",
    "                )\n",
    "                model.train(X_train, y_train)\n",
    "\n",
    "                y_pred_train = model.predict(X_train)\n",
    "                train_accuracy = model.accuracy(y_train, y_pred_train)\n",
    "                print(f\"Accuracy train: {train_accuracy * 100:.2f}%\")\n",
    "\n",
    "                y_pred_test = model.predict(X_test)\n",
    "                test_accuracy = model.accuracy(y_test, y_pred_test)\n",
    "                print(f\"Accuracy test: {test_accuracy * 100:.2f}%\")\n",
    "\n",
    "                # Validate the model\n",
    "                for validation_file, class_label in [\n",
    "                    (\"../calib_rec_tool/data_files/validation_moove_0.csv\", 19),\n",
    "                    (\"../calib_rec_tool/data_files/validation_moove_19.csv\", 11),\n",
    "                ]:\n",
    "                    df_validation = pd.read_csv(validation_file).drop(\n",
    "                        columns=[df.columns[0]]\n",
    "                    )\n",
    "                    X_val, y_val = (\n",
    "                        df_validation[features_to_keep].to_numpy(),\n",
    "                        df_validation.label.to_numpy(),\n",
    "                    )\n",
    "\n",
    "                    preprocessed_emg_data = preprocess_emg_data(X_val)\n",
    "                    segments, segment_labels = segment_signal(\n",
    "                        preprocessed_emg_data, y_val, w_s, ol\n",
    "                    )\n",
    "                    features = np.array(\n",
    "                        [extract_features(segment) for segment in segments]\n",
    "                    )\n",
    "\n",
    "                    X_train, X_test, y_train, y_test = train_test_split(\n",
    "                        features, segment_labels, test_size=0.9, random_state=model.seed\n",
    "                    )\n",
    "                    y_pred = model.predict(X_test)\n",
    "                    val_accuracy = model.accuracy(y_test, y_pred)\n",
    "                    print(\n",
    "                        f\"Accuracy validation (full class {class_label}): {val_accuracy * 100:.2f}%\"\n",
    "                    )\n",
    "                    final_results.append(\n",
    "                        ([w_s, ol, coff, f_s], round(val_accuracy * 100, 2))\n",
    "                    )\n",
    "\n",
    "final_results = sorted(final_results, key=lambda x: x[1], reverse=True)\n",
    "for params, result in final_results:\n",
    "    print(f\"Params: {params}, Result: {result}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ICARUS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
